{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "# Loat the right urlretrieve based on python version\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Useful for being able to dump images into the Notebook\n",
    "import IPython.display as D\n",
    "\n",
    "# Import CNTK and helpers\n",
    "import cntk as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isFast = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.device.try_set_default_device(C.device.gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# By default, we store data in the Examples/Image directory under CNTK\n",
    "# If you're running this _outside_ of CNTK, consider changing this\n",
    "data_root = os.path.join('..', 'Examples', 'Image')\n",
    "\n",
    "datasets_path = os.path.join(data_root, 'DataSets')\n",
    "output_path = os.path.join('.', 'temp', 'Output')\n",
    "\n",
    "def ensure_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  527M  100  527M    0     0  5847k      0  0:01:32  0:01:32 --:--:-- 6327k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O -S https://www.cntk.ai/Models/Caffe_Converted/VGG16_ImageNet_Caffe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VGG16_ImageNet_Caffe.model and printing all layers:\n",
      "  prob (1000,)\n",
      "  prob (1000,)\n",
      "  fc8 (1000,)\n",
      "  drop7 (4096,)\n",
      "  relu7 (4096,)\n",
      "  fc7 (4096,)\n",
      "  drop6 (4096,)\n",
      "  relu6 (4096,)\n",
      "  fc6 (4096,)\n",
      "  pool5 (512, 7, 7)\n",
      "  relu5_3 (512, 14, 14)\n",
      "  conv5_3 (512, 14, 14)\n",
      "  relu5_2 (512, 14, 14)\n",
      "  conv5_2 (512, 14, 14)\n",
      "  relu5_1 (512, 14, 14)\n",
      "  conv5_1 (512, 14, 14)\n",
      "  pool4 (512, 14, 14)\n",
      "  relu4_3 (512, 28, 28)\n",
      "  conv4_3 (512, 28, 28)\n",
      "  relu4_2 (512, 28, 28)\n",
      "  conv4_2 (512, 28, 28)\n",
      "  relu4_1 (512, 28, 28)\n",
      "  conv4_1 (512, 28, 28)\n",
      "  pool3 (256, 28, 28)\n",
      "  relu3_3 (256, 56, 56)\n",
      "  conv3_3 (256, 56, 56)\n",
      "  relu3_2 (256, 56, 56)\n",
      "  conv3_2 (256, 56, 56)\n",
      "  relu3_1 (256, 56, 56)\n",
      "  conv3_1 (256, 56, 56)\n",
      "  pool2 (128, 56, 56)\n",
      "  relu2_2 (128, 112, 112)\n",
      "  conv2_2 (128, 112, 112)\n",
      "  relu2_1 (128, 112, 112)\n",
      "  conv2_1 (128, 112, 112)\n",
      "  pool1 (64, 112, 112)\n",
      "  relu1_2 (64, 224, 224)\n",
      "  conv1_2 (64, 224, 224)\n",
      "  relu1_1 (64, 224, 224)\n",
      "  conv1_1 (64, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "base_model_file=\"VGG16_ImageNet_Caffe.model\"\n",
    "\n",
    "# Print out all layers in the model\n",
    "print('Loading {} and printing all layers:'.format(base_model_file))\n",
    "node_outputs = C.logging.get_node_outputs(C.load_model(base_model_file))\n",
    "for l in node_outputs: print(\"  {0} {1}\".format(l.name, l.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Composite(Combine): Input('data', [#], [3 x 224 x 224]) -> Output('prob', [#], [1000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.load_model(base_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define base model location and characteristics\n",
    "base_model_file=\"VGG16_ImageNet_Caffe.model\"\n",
    "base_model = {\n",
    "    'model_file': base_model_file,\n",
    "    'feature_node_name': 'data',\n",
    "    'last_hidden_node_name': 'drop7',\n",
    "    # Channel Depth x Height x Width\n",
    "    'image_dims': (3, 224, 224)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cntk.io.transforms as xforms\n",
    "ensure_exists(output_path)\n",
    "np.random.seed(123)\n",
    "\n",
    "# Creates a minibatch source for training or testing\n",
    "def create_mb_source(map_file, image_dims, num_classes, randomize=True):\n",
    "    transforms = [xforms.scale(width=image_dims[2], height=image_dims[1], channels=image_dims[0], interpolations='linear')]\n",
    "    return C.io.MinibatchSource(C.io.ImageDeserializer(map_file, C.io.StreamDefs(\n",
    "            features=C.io.StreamDef(field='image', transforms=transforms),\n",
    "            labels=C.io.StreamDef(field='label', shape=num_classes))),\n",
    "            randomize=randomize)\n",
    "\n",
    "# Creates the network model for transfer learning\n",
    "def create_model(model_details, num_classes, input_features, new_prediction_node_name='prediction', freeze=False):\n",
    "    # Load the pretrained classification net and find nodes\n",
    "    base_model = C.load_model(model_details['model_file'])\n",
    "    feature_node = C.logging.find_by_name(base_model, model_details['feature_node_name'])\n",
    "    last_node = C.logging.find_by_name(base_model, model_details['last_hidden_node_name'])\n",
    "    # Clone the desired layers with fixed weights\n",
    "    cloned_layers = C.combine([last_node.owner]).clone(\n",
    "        C.CloneMethod.freeze if freeze else C.CloneMethod.clone,\n",
    "        {feature_node: C.placeholder(name='features')})\n",
    "\n",
    "    # Add new dense layer for class prediction\n",
    "    feat_norm = input_features #FIXME - C.Constant(114)\n",
    "    cloned_out = cloned_layers(feat_norm)\n",
    "    z = C.layers.Dense(num_classes, activation=None, name=new_prediction_node_name) (cloned_out)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output('prob', [#], [1000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = C.load_model(base_model_file)\n",
    "m.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Trains a transfer learning model\n",
    "def train_model(model_details, num_classes, train_map_file,\n",
    "                learning_params, max_images=-1):\n",
    "    num_epochs = learning_params['max_epochs']\n",
    "    epoch_size = sum(1 for line in open(train_map_file))\n",
    "    if max_images > 0:\n",
    "        epoch_size = min(epoch_size, max_images)\n",
    "    minibatch_size = learning_params['mb_size']\n",
    "\n",
    "    # Create the minibatch source and input variables\n",
    "    minibatch_source = create_mb_source(train_map_file, model_details['image_dims'], num_classes)\n",
    "    image_input = C.input_variable(model_details['image_dims'])\n",
    "    label_input = C.input_variable(num_classes)\n",
    "\n",
    "    # Define mapping from reader streams to network inputs\n",
    "    input_map = {\n",
    "        image_input: minibatch_source['features'],\n",
    "        label_input: minibatch_source['labels']\n",
    "    }\n",
    "\n",
    "    # Instantiate the transfer learning model and loss function\n",
    "    tl_model = create_model(model_details, num_classes, image_input, freeze=learning_params['freeze_weights'])\n",
    "    ce = C.cross_entropy_with_softmax(tl_model, label_input)\n",
    "    pe = C.classification_error(tl_model, label_input)\n",
    "\n",
    "    # Instantiate the trainer object\n",
    "    lr_schedule = C.learning_rate_schedule(learning_params['lr_per_mb'], unit=C.UnitType.minibatch)\n",
    "    mm_schedule = C.momentum_schedule(learning_params['momentum_per_mb'])\n",
    "    learner = C.momentum_sgd(tl_model.parameters, lr_schedule, mm_schedule,\n",
    "                           l2_regularization_weight=learning_params['l2_reg_weight'])\n",
    "    trainer = C.Trainer(tl_model, (ce, pe), learner)\n",
    "\n",
    "    # Get minibatches of images and perform model training\n",
    "    print(\"Training transfer learning model for {0} epochs (epoch_size = {1}).\".format(num_epochs, epoch_size))\n",
    "    C.logging.log_number_of_parameters(tl_model)\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=num_epochs)\n",
    "    for epoch in range(num_epochs):       # loop over epochs\n",
    "        sample_count = 0\n",
    "        while sample_count < epoch_size:  # loop over minibatches in the epoch\n",
    "            data = minibatch_source.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map)\n",
    "            trainer.train_minibatch(data)                                    # update model with it\n",
    "            sample_count += trainer.previous_minibatch_sample_count          # count samples processed so far\n",
    "            progress_printer.update_with_trainer(trainer, with_metric=True)  # log progress\n",
    "            if sample_count % (100 * minibatch_size) == 0:\n",
    "                print (\"Processed {0} samples\".format(sample_count))\n",
    "\n",
    "        progress_printer.epoch_summary(with_metric=True)\n",
    "\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluates a single image using the re-trained model\n",
    "def eval_single_image(loaded_model, image_path, image_dims):\n",
    "    # load and format image (resize, RGB -> BGR, CHW -> HWC)\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        if image_path.endswith(\"png\"):\n",
    "            temp = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "            temp.paste(img, img)\n",
    "            img = temp\n",
    "        resized = img.resize((image_dims[2], image_dims[1]), Image.ANTIALIAS)\n",
    "        bgr_image = np.asarray(resized, dtype=np.float32)[..., [2, 1, 0]]\n",
    "        hwc_format = np.ascontiguousarray(np.rollaxis(bgr_image, 2))\n",
    "\n",
    "        # compute model output\n",
    "        arguments = {loaded_model.arguments[0]: [hwc_format]}\n",
    "        output = loaded_model.eval(arguments)\n",
    "\n",
    "        # return softmax probabilities\n",
    "        sm = C.softmax(output[0])\n",
    "        return sm.eval()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Could not open (skipping file): \", image_path)\n",
    "        return ['None']\n",
    "\n",
    "\n",
    "\n",
    "# Evaluates an image set using the provided model\n",
    "def eval_test_images(loaded_model, output_file, test_map_file, image_dims, max_images=-1, column_offset=0):\n",
    "    num_images = sum(1 for line in open(test_map_file))\n",
    "    if max_images > 0:\n",
    "        num_images = min(num_images, max_images)\n",
    "    if isFast:\n",
    "        num_images = min(num_images, 300) #We will run through fewer images for test run\n",
    "\n",
    "    print(\"Evaluating model output node '{0}' for {1} images.\".format('prediction', num_images))\n",
    "\n",
    "    pred_count = 0\n",
    "    correct_count = 0\n",
    "    np.seterr(over='raise')\n",
    "    with open(output_file, 'wb') as results_file:\n",
    "        with open(test_map_file, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                tokens = line.rstrip().split('\\t')\n",
    "                img_file = tokens[0 + column_offset]\n",
    "                probs = eval_single_image(loaded_model, img_file, image_dims)\n",
    "\n",
    "                if probs[0]=='None':\n",
    "                    print(\"Eval not possible: \", img_file)\n",
    "                    continue\n",
    "\n",
    "                pred_count += 1\n",
    "                true_label = int(tokens[1 + column_offset])\n",
    "                predicted_label = np.argmax(probs)\n",
    "                if predicted_label == true_label:\n",
    "                    correct_count += 1\n",
    "                else:\n",
    "                    print(\"Wrong prediction for: {0}: real {1}, predicted {2}\".format(img_file, true_label, predicted_label))\n",
    "\n",
    "                np.savetxt(results_file, probs[np.newaxis], fmt=\"%.3f\")\n",
    "                if pred_count % 100 == 0:\n",
    "                    print(\"Processed {0} samples ({1:.2%} correct)\".format(pred_count,\n",
    "                                                                           (float(correct_count) / pred_count)))\n",
    "                if pred_count >= num_images:\n",
    "                    break\n",
    "    print (\"{0} of {1} prediction were correct\".format(correct_count, pred_count))\n",
    "    return correct_count, pred_count, (float(correct_count) / pred_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "force_retraining = True\n",
    "\n",
    "max_training_epochs = 5 if isFast else 20\n",
    "\n",
    "learning_params = {\n",
    "    'max_epochs': max_training_epochs,\n",
    "    'mb_size': 50,\n",
    "    'lr_per_mb': [0.2]*10 + [0.1],\n",
    "    'momentum_per_mb': 0.9,\n",
    "    'l2_reg_weight': 0.0005,\n",
    "    'freeze_weights': True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set python version variable\n",
    "python_version = sys.version_info.major\n",
    "\n",
    "def create_map_file_from_folder(root_folder, class_mapping, include_unknown=False, valid_extensions=['.jpg', '.jpeg', '.png']):\n",
    "    map_file_name = os.path.join(root_folder, \"map.txt\")\n",
    "\n",
    "    map_file = None\n",
    "\n",
    "    if python_version == 3:\n",
    "        map_file = open(map_file_name , 'w', encoding='utf-8')\n",
    "    else:\n",
    "        map_file = open(map_file_name , 'w')\n",
    "\n",
    "    for class_id in range(0, len(class_mapping)):\n",
    "        folder = os.path.join(root_folder, class_mapping[class_id])\n",
    "        if os.path.exists(folder):\n",
    "            for entry in os.listdir(folder):\n",
    "                filename = os.path.abspath(os.path.join(folder, entry))\n",
    "                if os.path.isfile(filename) and os.path.splitext(filename)[1].lower() in valid_extensions:\n",
    "                    try:\n",
    "                        map_file.write(\"{0}\\t{1}\\n\".format(filename, class_id))\n",
    "                    except UnicodeEncodeError:\n",
    "                        continue\n",
    "\n",
    "    if include_unknown:\n",
    "        for entry in os.listdir(root_folder):\n",
    "            filename = os.path.abspath(os.path.join(root_folder, entry))\n",
    "            if os.path.isfile(filename) and os.path.splitext(filename)[1].lower() in valid_extensions:\n",
    "                try:\n",
    "                    map_file.write(\"{0}\\t-1\\n\".format(filename))\n",
    "                except UnicodeEncodeError:\n",
    "                    continue\n",
    "\n",
    "    map_file.close()\n",
    "\n",
    "    return map_file_name\n",
    "\n",
    "\n",
    "def create_class_mapping_from_folder(root_folder):\n",
    "    classes = []\n",
    "    for _, directories, _ in os.walk(root_folder):\n",
    "        for directory in directories:\n",
    "            classes.append(directory)\n",
    "    return np.asarray(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drinks_data = {\n",
    "        'training_folder': '/data/drinks/train',\n",
    "        'testing_folder': '/data/drinks/valid'\n",
    "    }\n",
    "\n",
    "drinks_data['class_mapping'] = create_class_mapping_from_folder(drinks_data['training_folder'])\n",
    "drinks_data['training_map'] = create_map_file_from_folder(drinks_data['training_folder'], drinks_data['class_mapping'])\n",
    "drinks_data['testing_map'] = create_map_file_from_folder(drinks_data['testing_folder'], drinks_data['class_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "drinks_model = {\n",
    "    'model_file': os.path.join(output_path, 'DrinksTransferLearning-VGG.model'),\n",
    "    'results_file': os.path.join(output_path, 'DrinksPredictions.txt'),\n",
    "    'num_classes': len(drinks_data['class_mapping'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transfer learning model for 5 epochs (epoch_size = 570).\n",
      "Training 12291 parameters in 2 parameter tensors.\n",
      "Finished Epoch[1 of 5]: [Training] loss = 3.989726 * 570, metric = 27.89% * 570 19.557s ( 29.1 samples/s);\n",
      "Finished Epoch[2 of 5]: [Training] loss = 0.966719 * 570, metric = 3.16% * 570 7.190s ( 79.3 samples/s);\n",
      "Finished Epoch[3 of 5]: [Training] loss = 0.317903 * 570, metric = 1.58% * 570 7.118s ( 80.1 samples/s);\n",
      "Finished Epoch[4 of 5]: [Training] loss = 0.037983 * 570, metric = 0.35% * 570 7.116s ( 80.1 samples/s);\n",
      "Finished Epoch[5 of 5]: [Training] loss = 0.000288 * 570, metric = 0.00% * 570 7.246s ( 78.7 samples/s);\n",
      "Stored trained model at ./temp/Output/DrinksTransferLearning-VGG.model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists(drinks_model['model_file']) and not force_retraining:\n",
    "    print(\"Loading existing model from %s\" % drinks_model['model_file'])\n",
    "    trained_model = C.load_model(drinks_model['model_file'])\n",
    "else:\n",
    "    trained_model = train_model(base_model,\n",
    "                                drinks_model['num_classes'], drinks_data['training_map'],\n",
    "                                learning_params)\n",
    "    trained_model.save(drinks_model['model_file'])\n",
    "    print(\"Stored trained model at %s\" % drinks_model['model_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model output node 'prediction' for 141 images.\n",
      "Wrong prediction for: /data/drinks/valid/valser/img014.jpg: real 1, predicted 0\n",
      "Processed 100 samples (99.00% correct)\n",
      "140 of 141 prediction were correct\n",
      "Done. Wrote output to ./temp/Output/DrinksPredictions.txt\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set\n",
    "predict_correct, predict_total, predict_accuracy = \\\n",
    "   eval_test_images(trained_model, drinks_model['results_file'], drinks_data['testing_map'], base_model['image_dims'])\n",
    "print(\"Done. Wrote output to %s\" % drinks_model['results_file'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
